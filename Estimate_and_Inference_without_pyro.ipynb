{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hellocybernetics/Pyro_tutorials/blob/master/Estimate_and_Inference_without_pyro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "hA-qlJZ9Nw4v",
        "colab_type": "code",
        "outputId": "bd2305a3-e28b-4f51-ec90-242ba95d7f51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install pyro-ppl"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyro-ppl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/5e/456d5bc24c010996c6d39ebe47680a5fa72c09b08146c15df23ba8945680/pyro-ppl-0.3.0.tar.gz (204kB)\n",
            "\u001b[K    100% |████████████████████████████████| 204kB 10.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: contextlib2 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (0.5.5)\n",
            "Requirement already satisfied: graphviz>=0.8 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (0.10.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (2.2)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (1.14.6)\n",
            "Collecting opt_einsum>=2.3.0 (from pyro-ppl)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/d6/44792ec668bcda7d91913c75237314e688f70415ab2acd7172c845f0b24f/opt_einsum-2.3.2.tar.gz (59kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (1.11.0)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (1.0.0)\n",
            "Requirement already satisfied: tqdm>=4.28 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (4.28.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.2->pyro-ppl) (4.3.2)\n",
            "Building wheels for collected packages: pyro-ppl, opt-einsum\n",
            "  Building wheel for pyro-ppl (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/ed/b5/01/c883fa6e02eb51fd67ba2b73f1ddcee42997716394792d57da\n",
            "  Building wheel for opt-einsum (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/51/3e/a3/b351fae0cbf15373c2136a54a70f43fea5fe91d8168a5faaa4\n",
            "Successfully built pyro-ppl opt-einsum\n",
            "Installing collected packages: opt-einsum, pyro-ppl\n",
            "Successfully installed opt-einsum-2.3.2 pyro-ppl-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "459cvjGfOGyN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Pyroの基本的な役割\n",
        "PyroはPyTorchを計算のバックエンドに構えた確率プログラミング言語です。確率プログラミング言語の主な役割は、様々な確率分布からのサンプリングや、同時分布・条件付き分布・周辺分布の取扱を容易にすることです。**まずはTorchを使ってみて、その確率プログラミング言語の必要性を体感してみましょう。**"
      ]
    },
    {
      "metadata": {
        "id": "77PKI6F3N6Ec",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.distributions as torchdist\n",
        "\n",
        "import pyro\n",
        "import pyro.distributions as dist\n",
        "import pyro.poutine as poutine"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LSELqDR0PTtu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 分布の記述\n",
        "まず、肩慣らしに標準正規分布 $\\rm {Normal} (0, 1)$ を書いてみましょう。`torch.distributions`  モジュールを使うことで下記のように記述することができます。"
      ]
    },
    {
      "metadata": {
        "id": "bPIXw1EnPDU2",
        "colab_type": "code",
        "outputId": "bb49fc5f-5b8b-4f88-ec18-f37277cb8f92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "normal_dist = torchdist.Normal(loc=torch.tensor(0.), scale=torch.tensor(1.))\n",
        "normal_dist"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Normal(loc: 0.0, scale: 1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "k93zrklnPuis",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### サンプリング\n",
        "続いて、記述した分布から\n",
        "$$\n",
        "x \\sim {\\rm Normal}(0, 1)\n",
        "$$\n",
        "とサンプリングを得るには下記のようにします。"
      ]
    },
    {
      "metadata": {
        "id": "9Apgnf6sQFe0",
        "colab_type": "code",
        "outputId": "b5d1cc7e-bc1e-4292-c2b2-c441d0c49916",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "x = normal_dist.sample()\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.2678)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "mq-6TcUIQPqS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "更に同じ分布から独立に複数のサンプルを得たい場合には下記のように、`sample()` メソッドに引数を渡すことで実施します。このとき引数はリストあるいはタプルで渡すようにします。"
      ]
    },
    {
      "metadata": {
        "id": "kc0-utrYQnVK",
        "colab_type": "code",
        "outputId": "3443ccd5-30d7-4409-e6ad-c4eef08723b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "X1 = normal_dist.sample([3,])\n",
        "X1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2863, 0.4209, 0.1714])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "Puq8R9cqRihc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "上記のサンプルは各成分が各々独立に正規分布から生成されています。数式で表現するならば下記のようになります。\n",
        "\n",
        "$$\n",
        "X_1[i] \\sim \\rm{Normal}(0, 1)\n",
        "$$\n",
        "\n",
        "同じ理屈でもっと多次元の配列を作ることもできます。"
      ]
    },
    {
      "metadata": {
        "id": "VzE_FNBCQqKa",
        "colab_type": "code",
        "outputId": "7b139324-d6b5-4eac-ed85-34e5ed1ed621",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "cell_type": "code",
      "source": [
        "X2 = normal_dist.sample([10, 2])\n",
        "X2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.2949, -0.1569],\n",
              "        [ 1.2726, -0.1090],\n",
              "        [-1.1460,  1.8392],\n",
              "        [-1.0977,  0.4679],\n",
              "        [-0.1797,  0.6231],\n",
              "        [-2.0613, -0.5645],\n",
              "        [ 0.1569,  0.4787],\n",
              "        [-1.0385, -0.1100],\n",
              "        [ 1.1162,  0.4524],\n",
              "        [ 0.7053,  0.9107]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "yfcsEdNdRvic",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "上記の配列も同様に各成分が独立に正規分布から生成されています。\n",
        "\n",
        "$$\n",
        "X_2[i, j] = \\rm{Normal}(0, 1)\n",
        "$$\n",
        "\n",
        "配列として取り出すと、もはや元々これが何の分布の話だったのか、情報を持ち合わせていないので注意が必要です。例えば、下記のような2次元正規分布を考えましょう。2次元正規分布からの1つのサンプルは当然2つの要素を持っています。"
      ]
    },
    {
      "metadata": {
        "id": "K5GrSGa7RBAK",
        "colab_type": "code",
        "outputId": "8ad02019-1b73-435e-874c-270258333333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "multi_normal_dist = torchdist.MultivariateNormal(\n",
        "    loc=torch.tensor([1., -2.]),\n",
        "    covariance_matrix=torch.tensor([[1., -1.,],\n",
        "                                    [-1., 2.]])\n",
        ")\n",
        "\n",
        "multi_normal_dist.sample()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.2670, -1.4106])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "metadata": {
        "id": "8gKtZFYpVB0C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "この2次元正規分布から10個のサンプルを得ると、`(10, 2)` の `tensor`が得られますが、この `tensor` の各成分は独立ではありません。各行は独立ですが、各列は2次元の正規分布からの一つのサンプルであり、相関を持っていることに注意する必要があります。\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "M1BGa6oXUILa",
        "colab_type": "code",
        "outputId": "ef0de7a3-7203-4912-f6dd-91fb5c00a665",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "cell_type": "code",
      "source": [
        "multi_normal_dist.sample([10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.5313, -0.2447],\n",
              "        [ 2.0379, -4.5415],\n",
              "        [ 0.8421, -1.4077],\n",
              "        [ 1.0975, -1.6367],\n",
              "        [-0.6248,  1.5462],\n",
              "        [ 2.4693, -3.2657],\n",
              "        [ 1.5901, -4.5817],\n",
              "        [ 1.0574, -3.1958],\n",
              "        [ 0.7431, -2.0510],\n",
              "        [ 0.6222, -0.6655]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "metadata": {
        "id": "sHtUrjA7VszA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "長いコードを書いているうちに、ある`tensor` がどういうサンプルのされ方をしたものであったのかを見失うことも起こりうるので注意が必要です。"
      ]
    },
    {
      "metadata": {
        "id": "ED47SK9QVuBv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 尤度の計算\n",
        "機械学習ではしばしば確率分布 $p(x)$ の尤度の計算が必要になります。あるサンプル $x^*$ の $p(x)$ における尤度は単純に $p(x^*)$ の値になります。では $\\{x_1, x_2, x_3,...,\\}$ の尤度はどのように計算するのかというと、\n",
        "\n",
        "$$\n",
        "p(x_1)p(x_2)p(x_3)...\n",
        "$$\n",
        "\n",
        "と各確率値の積によって表されます。確率値は $[0, 1]$ の値でありサンプルの数が多くなると、$1$ 未満の数の積が連なり非常に小さな値となってしまいます。そこで、コンピュータでは通常、対数尤度というものを計算することにします。\n",
        "\n",
        "$$\n",
        "{\\rm log}\\{p(x_1)p(x_2)p(x_3)...\\} = {\\rm log}p(x_1) + {\\rm log}p(x_2) + {\\rm log}p(x_3) + ...\n",
        "$$\n",
        "\n",
        "と負の値の足し算になり数値的に安定します。また、$\\rm log$ は単調増加関数であるので、微分にとっても符号には影響が無く（絶対値には影響するが）、積が和となっているため都合が良いです。サンプル $x^*$ の対数尤度は簡単に下記のコードで求まります。"
      ]
    },
    {
      "metadata": {
        "id": "1LnrmXtHWQs8",
        "colab_type": "code",
        "outputId": "2ba54fd0-0b83-49c5-f209-83edba9d8b47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "sample = multi_normal_dist.sample()\n",
        "print(\"*** a sample from 2dim normal: \\n\", sample)\n",
        "log_likelihood = multi_normal_dist.log_prob(sample)\n",
        "print(\"*** log likelihood of the sample \\n\", log_likelihood)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*** a sample from 2dim normal: \n",
            " tensor([ 1.9878, -4.1139])\n",
            "*** log likelihood of the sample \n",
            " tensor(-2.9599)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qZb5n79oWebI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "また複数のサンプルに関しては足し算する前の各々の対数尤度が返ってきます。"
      ]
    },
    {
      "metadata": {
        "id": "KRHth-wsYfF-",
        "colab_type": "code",
        "outputId": "64527f70-38de-4deb-e35d-3e08e592ee56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "samples = multi_normal_dist.sample([5,])\n",
        "print(\"*** 5 samples from 2dim normal: \\n\", sample)\n",
        "log_likelihoods = multi_normal_dist.log_prob(samples)\n",
        "print(\"*** log likelihoods of the samples: \\n\", log_likelihoods)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*** 5 samples from 2dim normal: \n",
            " tensor([ 1.9878, -4.1139])\n",
            "*** log likelihoods of the samples: \n",
            " tensor([-2.2946, -1.8613, -3.4462, -3.3157, -3.2250])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wy4ONNQrYkgi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### MAP推定\n",
        "ここでMAP推定を実施してみます。上記の関数と自動微分機能を駆使すれば難しくありません。\n",
        "\n",
        "#### 訓練データ\n",
        "人工訓練データを作りますが、パラメータは知らない体で推定をします。"
      ]
    },
    {
      "metadata": {
        "id": "M1mu_XCBZ-8e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def toy_data():\n",
        "    true_mu = torch.tensor([2., 3.])\n",
        "    true_cov = torch.tensor([[2., -3.],[-3, 5]])\n",
        "    \n",
        "    X = torchdist.MultivariateNormal(loc=true_mu, \n",
        "                                     covariance_matrix=true_cov).sample([100,])\n",
        "    return X\n",
        "\n",
        "X_train = toy_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RePK_G1Kac-j",
        "colab_type": "code",
        "outputId": "52fef6ba-ffea-4683-e7e4-eeea10c8117c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(X_train.numpy()[:,0], X_train.numpy()[:,1], \"o\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fdf772ad160>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAFKCAYAAABcq1WoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAACfEb4AAPjs/wPBv0EkRjEy8AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "2C3CoLtMbFP-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 推定のためのモデル\n",
        "データを可視化して、コレは2次元正規分布に従っていると睨んだとしましょう。すると私達が推定したいパラメータは、平均ベクトルと共分散行列になります。これらをまず初期化しておきます。"
      ]
    },
    {
      "metadata": {
        "id": "O5WouLd4beCO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mu_param = torch.nn.Parameter(torch.tensor([0., 0.]))\n",
        "cov_tril_param = torch.nn.Parameter(torch.tensor([[1., 0.],\n",
        "                                                  [0., 1.]]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IdOxDc-Nc0gP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 対数尤度関数（最適化の目的関数）\n",
        "データ $X = \\{x_1, \\cdots, x_N\\}$ に対する対数尤度関数は\n",
        "\n",
        "$$\n",
        "{\\rm LogLikelihood}(X, \\mu, \\Sigma) = \\frac{1}{N}\\sum_{i=1}^N {\\rm log}\\{{\\rm Normal}(x_i \\mid \\mu, \\Sigma)\\}\n",
        "$$\n",
        "\n",
        "であり、データ $X$ は既に手元にあるので、パラメータ $\\mu, \\Sigma$ に関して最大化するのが最尤推定法になります。続いて事前分布 $p(\\mu)$ と $p(\\Sigma)$ を目的関数に考慮するのがMAP推定になります。具体的には下記のように修正されます。\n",
        "\n",
        "$$\n",
        "{\\rm LogJointProb}(X, \\mu, \\Sigma) = \\frac{1}{N}\\sum_{i=1}^N {\\rm log}\\{{\\rm Normal}(x_i \\mid \\mu, \\Sigma)\\} + {\\rm log}p(\\mu) +{\\rm log}p(\\Sigma)\n",
        "$$\n",
        "\n",
        "今回は適当に分散の大きな正規分布を仮定し、無情報事前分布に近い状態にしておきます。\n",
        "\n",
        "#### 補足\n",
        "ちなみにベイズの定理よりパラメータの事後分布は\n",
        "\n",
        "$$\n",
        "p(\\mu, \\Sigma \\mid X) = \\frac{p(X, \\mu, \\Sigma)}{p(X)}\n",
        "$$\n",
        "\n",
        "と表され、この分母は定数になっています。したがって分子の同時分布について最大化すれば良いというのかMAP推定であり、同時分布を\n",
        "\n",
        "$$\n",
        "p(X,\\mu,\\Sigma)=p(X\\mid \\mu, \\Sigma) p(\\mu) p(\\Sigma)\n",
        "$$\n",
        "\n",
        "と表現しつつ、対数を取ることで上記の目的関数が導出されます。"
      ]
    },
    {
      "metadata": {
        "id": "Iya1lNR9b2Eu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def log_joint_prob(mu_param, cov_param, X):\n",
        "    \n",
        "    prior_mu = torchdist.Normal(loc=torch.zeros_like(mu_param),\n",
        "                                 scale=100*torch.ones_like(mu_param))\n",
        "    prior_cov = torchdist.Normal(loc=torch.zeros_like(cov_param),\n",
        "                                 scale=100*torch.ones_like(cov_param))\n",
        "    \n",
        "    model = torchdist.MultivariateNormal(\n",
        "        loc=mu_param, \n",
        "        scale_tril=cov_param\n",
        "    )\n",
        "    \n",
        "    return (\n",
        "        model.log_prob(X).mean() \n",
        "        + prior_mu.log_prob(mu_param).mean()\n",
        "        + prior_cov.log_prob(cov_param).mean()\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mkk01MKRd2UZ",
        "colab_type": "code",
        "outputId": "d06a9951-5375-4a7d-84c9-28931bd8a3f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"*** initial log joint prob\")\n",
        "log_joint_prob(mu_param, cov_param, X_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*** initial log joint prob\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-50.0842, grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "metadata": {
        "id": "_bOHbf89kWuo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(params=[mu_param, cov_param], lr=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FyyuYqyEkw3b",
        "colab_type": "code",
        "outputId": "971dc70f-607d-4387-cd80-e6bf190368d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        }
      },
      "cell_type": "code",
      "source": [
        "for i in range(30000):\n",
        "    optimizer.zero_grad()\n",
        "    log_joint_prob_value = log_joint_prob(mu_param, cov_param, X_train)\n",
        "    loss_value = - log_joint_prob_value\n",
        "    loss_value.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if (i+1) % 1000 == 0 or (i==0):\n",
        "        print(loss_value.detach().numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50.084183\n",
            "19.342072\n",
            "16.561716\n",
            "15.502459\n",
            "14.844397\n",
            "14.425766\n",
            "14.276202\n",
            "14.093371\n",
            "14.005144\n",
            "14.0023\n",
            "14.001698\n",
            "14.00165\n",
            "14.00165\n",
            "14.00165\n",
            "14.00165\n",
            "14.00165\n",
            "14.00165\n",
            "14.00165\n",
            "14.00165\n",
            "14.00165\n",
            "14.00165\n",
            "14.00165\n",
            "14.00165\n",
            "14.00165\n",
            "14.00165\n",
            "14.00165\n",
            "14.00165\n",
            "14.00165\n",
            "14.00165\n",
            "14.00165\n",
            "14.00165\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w0AAZ-oPlakF",
        "colab_type": "code",
        "outputId": "17212c69-ac69-4d8d-bef4-a58602316744",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "def toy_data():\n",
        "    true_mu = torch.tensor([2., 3.])\n",
        "    true_cov = torch.tensor([[2., -3.],\n",
        "                             [-3., 5.]])\n",
        "    \n",
        "    X = torchdist.MultivariateNormal(loc=true_mu, \n",
        "                                     covariance_matrix=true_cov).sample([100,])\n",
        "    return X\n",
        "\"\"\"\n",
        "\n",
        "print(\"mu map estimated: \\n\", mu_param.data)\n",
        "print(\"cov map estimated \\n\", cov_param.mm(cov_param.t()).data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mu map estimated: \n",
            " tensor([1.9398, 3.0057])\n",
            "cov map estimated \n",
            " tensor([[ 2.3563, -3.8066],\n",
            "        [-3.8066,  6.6836]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5qLM4A32m_Ko",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 回帰モデル\n",
        "次に同じようにTorchで回帰モデルを実装していきます。スカラーの入力 $x$ とスカラーの出力 $y$ の関係性が下記の用に多項式で表されると仮定しましょう。\n",
        "\n",
        "$$\n",
        "y = -3 + 4x + x^2 + \\epsilon\n",
        "$$\n",
        "\n",
        "ただし、ここで $\\epsilon \\sim {\\rm Normal}(0, 1)$ の正規乱数としておきます。"
      ]
    },
    {
      "metadata": {
        "id": "oRiDD1Ux1vP4",
        "colab_type": "code",
        "outputId": "a407ae07-8f1a-40f2-f868-014a3478cde3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "cell_type": "code",
      "source": [
        "def toy_poly():\n",
        "    \n",
        "    x = 5 * torch.rand(100, 1) \n",
        "    linear_op = -3 - 4*x + 1*x**2 \n",
        "    y = torchdist.Normal(linear_op, 1).sample()\n",
        "    return x, y\n",
        "\n",
        "x_train, y_train = toy_poly()\n",
        "\n",
        "plt.plot(x_train.numpy(), y_train.numpy(), \"o\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fdf7701a7f0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAFKCAYAAABcq1WoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "G4wncEBU2n3x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### モデル\n",
        "さて、上記のデータを見て、二次関数で表現できると睨んだとしましょう（出来レースですが）。\n",
        "\n",
        "$$\n",
        "y = w_0 + w_1x + w_2x^2 + \\epsilon\n",
        "$$\n",
        "\n",
        "すると、簡単な式変形から下記のような確率モデルを使うことが考えられます（$\\epsilon$の分散は既知としているが、未知にすることも当然必要であれば考えられる）。 \n",
        "\n",
        "\n",
        "$$\n",
        "y - (w_0 + w_1x + w_2x^2) \\sim {\\rm Normal}(0,1)\n",
        "$$\n",
        "\n",
        "あるいは、分布の平均の方にパラメータを持つ項を吸収させて\n",
        "\n",
        "$$\n",
        "y \\sim {\\rm Normal}(w_0 + w_1x + w_2x^2 ,1)\n",
        "$$\n",
        "\n",
        "とできます。事前分布を適当に置いてしまえば、MAP推定に必要な同時分布 $p(w_0, w_1, w_2, x, y)$ が一先ず書き下せますので、その対数値を最大化することで回帰問題を解くことが可能になります。今回も各パラメータに対してはそれぞれ適当な正規分布を仮定してしまいましょう。\n",
        "\n",
        "$$\n",
        "{\\rm LogJointProb}(w_0, w_1, w_2, X, Y) = \\frac{1}{N} \\sum_{i=1}^N {\\rm Normal}(y_i\\mid w_0 + w_1x_i + w_2x_i^2 ,1) +{\\rm log} p(w_0) +{\\rm log} p(w_1) +{\\rm log} p(w_2)\n",
        "$$"
      ]
    },
    {
      "metadata": {
        "id": "LmDgr1854-ZS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "w0 = torch.nn.Parameter(torch.tensor(1.))\n",
        "w1 = torch.nn.Parameter(torch.tensor(1.))\n",
        "w2 = torch.nn.Parameter(torch.tensor(1.))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yM3nPHcf5J25",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def log_joint_prob(w0, w1, w2, x, y):\n",
        "    \n",
        "    pass\n",
        "\n",
        "    ## w0, w1, w2 の事前分布を書く\n",
        "    \n",
        "    \n",
        "    \n",
        "    ## 尤度関数 N(w0 + w1*x + w2*x**2, 1)を書く\n",
        "    \n",
        "    \n",
        "    \n",
        "    ## 対数事後確率を返す\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hh15BgdT-v3M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 変分推論\n",
        "ベイズ推論は事後分布 \n",
        "\n",
        "$$\n",
        "p(\\theta \\mid D) = \\frac{p(D\\mid \\theta)p(\\theta)}{p(D)}\n",
        "$$\n",
        "\n",
        "において、同時分布の最大化に甘んじず（すなわち関数の一番山となる部分だけを探すのではなく）、分布の形状全体を把握しようという試みになります。その試みは一般に困難を極めます。都合の良い尤度関数と都合の良い事前分布を選ばない限りは形状全体を上手に求めることはできません。\n",
        "\n",
        "したがって、形状全体を知りたいのだが、ある程度簡略化した形状で一番近いものを探せればいいというのが変分推論です。変分モデル $q(\\theta; \\eta)$ を仮定し（$\\eta$は変分パラメータと呼ばれる最適化すべきパラメータである）、$\\eta$ の調整で分布の形状を変えること $p(\\theta |D)$ に最も近い $q(\\theta; \\eta)$ を決定します。近いというのはKLダイバージェンスの意味であり\n",
        "\n",
        "$$\n",
        "{\\rm KL}[q(\\theta; \\eta) : p(\\theta\\mid D)] = {\\mathbb E}_{q(\\theta;\\eta)}[{\\rm log}q(\\theta; \\eta)] - {\\mathbb E}_{q(\\theta;\\eta)}[{\\rm log}p(\\theta)] - {\\mathbb E}_{q(\\theta;\\eta)}[{\\rm log}p(D\\mid\\theta)]\n",
        "$$\n",
        "\n",
        "を最小化するような $\\eta$ を求めます。\n",
        "\n",
        "こちらも最適化問題ではありますが、求めているものはパラメータ $\\theta $ の値ではなくパラメータ $\\theta$ が取りうる値の分布を網羅的に把握するために $\\eta$ を最適化していることに注意しましょう。最適化された $\\eta$ によって分布 $q(\\theta ; \\eta)$ が定まり、この分布からサンプリングをしたりすることで、単に点推定で $\\theta$ を決めてしまうよりも多くの情報を利用することができるというわけです。\n",
        "\n",
        "実際の推論では期待値計算の代わりに現在の $\\eta$ の値を用いて \n",
        "\n",
        "$$\n",
        "\\theta^* \\sim q(\\theta; \\eta)\n",
        "$$\n",
        "\n",
        "とサンプリングし、サンプリングされた$\\theta^*$ で現在のKLダイバージェンスを計算するということにします（そんなのいい加減すぎる！と思うのであれば、$q(\\theta; \\eta)$ は現在の $\\eta$ を使うとして重点サンプリングなどをしてもいいだろうし、大げさにもMCMCを使ってもいいだろう。単に計算量の問題である）。\n",
        "\n",
        "$$\n",
        "{\\rm KL}[q(\\theta; \\eta) : p(\\theta\\mid D)] \\simeq {\\rm log}q(\\theta^*; \\eta) - {\\rm log}p(\\theta^*) - {\\rm log}p(D\\mid\\theta^*)\n",
        "$$\n",
        "\n",
        "\n",
        "#### 変分モデル\n",
        "回帰問題の例に戻って、パラメータ $w_0, w_1, w_2$ に対してそれぞれ変分モデル\n",
        "\n",
        "$$\n",
        "q(w_i ; \\eta_i) = {\\rm Normal}(\\mu_i, \\sigma_i)\n",
        "$$\n",
        "\n",
        "を仮定しましょう。すなわち各 $w_i$ に対して正規分布を仮定して、あとはそれぞれの平均分散を変分パラメータとして最適化して $w_i$ の分布を得てしまおうということにしたのです。"
      ]
    },
    {
      "metadata": {
        "id": "n4xTF9EUCD-D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "variatinal_params = {\n",
        "    \"w0_loc\": torch.nn.Parameter(torch.tensor(0.)),\n",
        "    \"w0_scale\": torch.nn.Parameter(torch.tensor(1.)),\n",
        "    \"w1_loc\": torch.nn.Parameter(torch.tensor(0.)),\n",
        "    \"w1_scale\": torch.nn.Parameter(torch.tensor(1.)),\n",
        "    \"w2_loc\": torch.nn.Parameter(torch.tensor(0.)),\n",
        "    \"w2_scale\": torch.nn.Parameter(torch.tensor(1.)),\n",
        "}\n",
        "\n",
        "def variatinal_model(variational_params):\n",
        "    \"\"\"\n",
        "    Variational model q(w; eta)\n",
        "    arg: variational parameters \"eta\"\n",
        "    return: w ~ q(w; eta)\n",
        "    \"\"\"\n",
        "    w0_q = torchdist.Normal(\n",
        "        variational_params[\"w0_loc\"],\n",
        "        variational_params[\"w0_scale\"],\n",
        "    )\n",
        "    \n",
        "    w1_q = torchdist.Normal(\n",
        "        variational_params[\"w1_loc\"],\n",
        "        variational_params[\"w1_scale\"],\n",
        "    )\n",
        "    \n",
        "    w2_q = torchdist.Normal(\n",
        "        variational_params[\"w2_loc\"],\n",
        "        variational_params[\"w2_scale\"],\n",
        "    )\n",
        "    \n",
        "    return w0_q, w1_q, w2_q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "huYHejDTJOSy",
        "colab_type": "code",
        "outputId": "6b95d9a2-3949-41b0-a488-222b45471957",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"*** w0, w1, w2 :variational model with initial variatinal params\")\n",
        "variatinal_model(variatinal_params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*** w0, w1, w2 :variational model with initial variatinal params\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Normal(loc: 0.0, scale: 1.0),\n",
              " Normal(loc: 0.0, scale: 1.0),\n",
              " Normal(loc: 0.0, scale: 1.0))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "metadata": {
        "id": "UrU74P8QJdKv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### KLダイバージェンス\n",
        "変分モデルを書き終えたので、後は変分モデルから出てくるサンプルを引数としたKLダイバージェンスを書き下せばいいです。KLダイバージェンスの近似は実は下記の通り、MAP推定でも利用してきたLog Joint Prob（データ $D$とパラメータ $\\theta$の対数同時確率）\n",
        "と新たに出てきたVariational model （勝手に仮定したパラメータ $\\theta $ の事後分布）の対数確率値で構成されています。\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "{\\rm KL}[q(\\theta; \\eta) : p(\\theta\\mid D)] &\\simeq {\\rm log}q(\\theta^*; \\eta) - {\\rm log}p(\\theta^*) - {\\rm log}p(D\\mid\\theta^*) \\\\\\ \n",
        "& = {\\rm log}q(\\theta^*; \\eta) - {\\rm LogJointProb}(\\theta^*, D)\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "ですので、実装上はMAP推定に使っていた目的関数をそのまま流用できます。\n",
        "\n",
        "すなわち実装は、$\\eta$ の関数である変分モデルを作り、パラメータ $\\theta$ をサンプリングできるようにして、そのサンプリング値$\\theta^*$をMAP推定で使っていた目的関数に代入してやれば良いのです。更に、サンプリングされた $\\theta^*$の$q(\\theta; \\eta)$ におけるの対数確率値も追加してやれば、目的関数の作成は終了です。"
      ]
    },
    {
      "metadata": {
        "id": "fkMzu9zJNNPp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def kl_divergence(variational_params, x, y):\n",
        "    w0_q, w1_q, w2_q = variatinal_model(variational_params)\n",
        "    \n",
        "    w0_sample = w0_q.sample()\n",
        "    w1_sample = w1_q.sample()    \n",
        "    w2_sample = w2_q.sample()\n",
        "    \n",
        "    log_joint_prob_value = log_joint_prob(w0_sample, w1_sample, w2_sample, x, y)\n",
        "    log_variational_prob_value = (\n",
        "        w0_q.log_prob(w0_sample) +\n",
        "        w1_q.log_prob(w1_sample) +\n",
        "        w2_q.log_prob(w2_sample)\n",
        "    )\n",
        "    \n",
        "    return log_variational_prob_value - log_joint_prob_value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-eCSuQ4cP2ua",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}